package fragmentation

import (
	"crypto/sha256"
	"encoding/binary"
	"sync"
	"time"

	"github.com/guabee/bnrtc/buffer"
)

type CachedChunkFragmentDataValue struct {
	lock              sync.Locker
	chunks            map[uint32]*FragmentData //<Id, *ChunkFragmentData>
	multiFragmentData *FragmentData
	updateTime        time.Time
	expiredTimer      *time.Timer
}

type FragmentType uint8

const (
	FragmentTypeSingle FragmentType = 0
	FragmentTypeMulti  FragmentType = 1
	FragmentTypeChunk  FragmentType = 2

	// 可选发送项
	// success，完成某一个Single/Multi的数据包收集
	FragmentTypeSuccess FragmentType = 3
	// 可选发送项
	// 可能是timeout，某一个MultiId的数据包缓存过久（30s）一直没有同样MultiId的数据包进来，就会触发自动清理，同时发送失败信号回去。
	// 也有可能是数据包id对不上号，有错乱现象
	FragmentTypeFailed FragmentType = 4
)

type FragmentData struct {
	Type    FragmentType
	Id      uint64 // is generated by data
	ChunkId uint32 // only for FragmentTypeChunk
	Digest  uint32
	Body    *buffer.Buffer
}

type FragmentOption struct {
	MaxFragmentSize      uint32 `json:"maxFragmentSize"`
	MaxFragmentChunkSize uint32 `json:"maxFragmentChunkSize"`
	ExpiredTimeSeconds   uint32 `json:"expiredTimeSeconds"`
}

type Fragmentation struct {
	MaxFragmentSize                   uint32
	maxFragmentChunkSize              uint32
	expiredTimeSeconds                uint32
	cachedChunkFragmentDataMap        *sync.Map //<MultiId, *CachedChunkFragmentDataValue>
	waitingChunksMultiFragmentDataMap *sync.Map //<MultiId, *MultiFragmentData>
}

func (data *FragmentData) GetBuffer() *buffer.Buffer {
	data.Body.PutU32(data.Digest)
	data.Body.PutU32(data.ChunkId)
	data.Body.PutU64(data.Id)
	data.Body.PutU8(uint8(data.Type))
	return data.Body
}

func (data *FragmentData) GetBytes() []byte {
	return data.GetBuffer().Data()
}

func FromBuffer(buf *buffer.Buffer) *FragmentData {
	if buf == nil || buf.Len() < 17 {
		return nil
	}
	dataType := buf.PullU8()
	dataId := buf.PullU64()
	multiId := buf.PullU32()
	digest := buf.PullU32()
	return &FragmentData{
		Type:    FragmentType(dataType),
		Id:      dataId,
		ChunkId: multiId,
		Digest:  digest,
		Body:    buf.Buffer(),
	}
}

func FromBytes(dataBytes []byte) *FragmentData {
	return FromBuffer(buffer.FromBytes(dataBytes))
}

func min32(a, b uint32) uint32 {
	if a < b {
		return a
	}
	return b
}

func getDigest(data []byte) uint32 {
	sum := sha256.Sum256(data)
	return binary.BigEndian.Uint32(sum[:4])
}

func getDataId(data []byte) uint64 {
	sum := sha256.Sum256(data)
	return binary.BigEndian.Uint64(sum[:8])
}

func checkDigest(data []byte, digest uint32) bool {
	return getDigest(data) == digest
}

func checkDataId(data []byte, id uint64) bool {
	return getDataId(data) == id
}

func NewFragmentation(opt *FragmentOption) *Fragmentation {
	if opt == nil {
		opt = &FragmentOption{
			MaxFragmentSize:      10 * 1024 * 1024,
			MaxFragmentChunkSize: 1000,
			ExpiredTimeSeconds:   10,
		}
	} else {
		if opt.MaxFragmentSize == 0 {
			opt.MaxFragmentSize = 10 * 1024 * 1024
		}
		if opt.MaxFragmentChunkSize == 0 {
			opt.MaxFragmentChunkSize = 1000
		}
		if opt.ExpiredTimeSeconds == 0 {
			opt.ExpiredTimeSeconds = 10
		}
	}

	return &Fragmentation{
		cachedChunkFragmentDataMap:        &sync.Map{},
		waitingChunksMultiFragmentDataMap: &sync.Map{},
		maxFragmentChunkSize:              opt.MaxFragmentChunkSize,
		expiredTimeSeconds:                opt.ExpiredTimeSeconds,
		MaxFragmentSize:                   opt.MaxFragmentSize,
	}
}

func (f *Fragmentation) Packetize(data []byte) []*FragmentData {
	if len(data) == 0 || len(data) > int(f.MaxFragmentSize) {
		return nil
	}

	totalLen := uint32(len(data))
	fragmentDataList := make([]*FragmentData, 0)

	if totalLen <= f.maxFragmentChunkSize {
		fragmentDataList = append(fragmentDataList, &FragmentData{
			Id:     getDataId(data),
			Type:   FragmentTypeSingle,
			Digest: getDigest(data),
			Body:   buffer.FromBytes(data),
		})
	} else {
		/// 第一帧是multi，后面几帧是chunk，不过帧的顺序并不重要，因为要全部接收到后才能正式处理
		headFragmentData := &FragmentData{
			Id:     getDataId(data),
			Type:   FragmentTypeMulti,
			Digest: getDigest(data),
			Body:   buffer.NewBuffer(0, nil),
		}
		headFragmentData.Body.PutU32(uint32(totalLen))
		fragmentDataList = append(fragmentDataList, headFragmentData)
		offset := uint32(0)
		remaining := totalLen
		chunkID := uint32(0)
		for remaining != 0 {
			dataBodySize := min32(f.maxFragmentChunkSize, remaining)
			dataBody := data[offset : offset+dataBodySize]
			chunkFragmentData := &FragmentData{
				Id:      headFragmentData.Id,
				Type:    FragmentTypeChunk,
				ChunkId: chunkID,
				Digest:  getDigest(dataBody),
				Body:    buffer.FromBytes(dataBody),
			}
			fragmentDataList = append(fragmentDataList, chunkFragmentData)
			remaining -= dataBodySize
			offset += dataBodySize
			chunkID++
		}
		headFragmentData.Body.PutU32(chunkID) // 写入chunk数量
	}
	return fragmentDataList
}

func (f *Fragmentation) UnPacketize(data []byte) (res []byte) {
	fragmentData := FromBytes(data)
	if fragmentData == nil {
		return nil
	}

	if fragmentData.Type == FragmentTypeSingle {
		dataBody := fragmentData.Body.Data()
		if !checkDigest(dataBody, fragmentData.Digest) {
			return nil
		}

		return dataBody
	} else if fragmentData.Type == FragmentTypeMulti {
		// 可能已经有下载的数据包，读取它
		if val, ok := f.cachedChunkFragmentDataMap.Load(fragmentData.Id); ok {
			chunkFragmentDataList := val.(*CachedChunkFragmentDataValue)
			chunkFragmentDataList.lock.Lock()
			chunkFragmentDataList.multiFragmentData = fragmentData
			res = chunkFragmentDataList.tryMergeChunks(fragmentData.Id, f)
			chunkFragmentDataList.lock.Unlock()
		} else {
			chunkFragmentDataList := &CachedChunkFragmentDataValue{
				lock:              &sync.Mutex{},
				chunks:            make(map[uint32]*FragmentData),
				multiFragmentData: fragmentData,
				updateTime:        time.Now(),
				expiredTimer:      f.newExpireTimer(fragmentData.Id),
			}
			f.cachedChunkFragmentDataMap.Store(fragmentData.Id, chunkFragmentDataList)
		}
	} else if fragmentData.Type == FragmentTypeChunk {
		dataBody := fragmentData.Body.Data()
		if !checkDigest(dataBody, fragmentData.Digest) {
			return nil
		}

		if val, ok := f.cachedChunkFragmentDataMap.Load(fragmentData.Id); ok {
			chunkFragmentDataList := val.(*CachedChunkFragmentDataValue)
			chunkFragmentDataList.lock.Lock()
			chunkFragmentDataList.chunks[fragmentData.ChunkId] = fragmentData
			res = chunkFragmentDataList.tryMergeChunks(fragmentData.Id, f)
			chunkFragmentDataList.lock.Unlock()
		} else {
			chunkFragmentDataList := &CachedChunkFragmentDataValue{
				lock:         &sync.Mutex{},
				chunks:       make(map[uint32]*FragmentData),
				updateTime:   time.Now(),
				expiredTimer: f.newExpireTimer(fragmentData.Id),
			}
			chunkFragmentDataList.chunks[fragmentData.ChunkId] = fragmentData
			f.cachedChunkFragmentDataMap.Store(fragmentData.Id, chunkFragmentDataList)
		}
	} else if fragmentData.Type == FragmentTypeFailed {
		/// 统计丢包，尝试重发
		return
	} else if fragmentData.Type == FragmentTypeSuccess {
		/// 统计发包成功
		return
	}

	return
}

func (f *Fragmentation) newExpireTimer(dataId uint64) *time.Timer {
	return time.AfterFunc(time.Duration(f.expiredTimeSeconds)*time.Second, func() {
		f.cachedChunkFragmentDataMap.Delete(dataId)
	})
}

/// 尝试合并下载完的数据包，失败则自动发送数据
func (ccfdv *CachedChunkFragmentDataValue) tryMergeChunks(dataId uint64, f *Fragmentation) (fullBodyBytes []byte) {
	/// 尝试合并下载完的数据包
	if fullBodyBytes, ok := ccfdv._tryMergeChunks(f.MaxFragmentSize); ok {
		/// 合并成功，可以删除缓存了并返回合并结果
		if fullBodyBytes != nil {
			f.cachedChunkFragmentDataMap.Delete(dataId)
			ccfdv.expiredTimer.Stop()
			if checkDataId(fullBodyBytes, ccfdv.multiFragmentData.Id) {
				return fullBodyBytes
			} else {
				return nil
			}
		} else {
			/// 数据包还没下载完，继续收集
			ccfdv.updateTime = time.Now()
		}
	} else {
		/// 合并失败，释放缓存，并发送失败通知
		f.cachedChunkFragmentDataMap.Delete(dataId)
		ccfdv.expiredTimer.Stop()
	}
	return nil
}

/// 尝试合并下载完的数据包
func (ccfdv *CachedChunkFragmentDataValue) _tryMergeChunks(maxLen uint32) (fullBodyBytes []byte, ok bool) {
	multiFragmentData := ccfdv.multiFragmentData
	if multiFragmentData != nil {
		if multiFragmentData.Body.Len() < 8 {
			return nil, false
		}

		chunkNum := multiFragmentData.Body.PeekU32(0)
		/// 如果已经下载的数据包都全了，那么就可以直接进行合并
		if uint32(len(ccfdv.chunks)) == chunkNum {
			totalLen := multiFragmentData.Body.PeekU32(4)
			if totalLen > maxLen {
				return nil, false
			}
			fullBodyBytes = make([]byte, totalLen)
			offset := uint32(0)
			for chunkId := uint32(0); chunkId < chunkNum; chunkId++ {
				if chunkFragmentData, ok := ccfdv.chunks[chunkId]; ok {
					chunkLen := chunkFragmentData.Body.Len()
					if chunkLen > totalLen-offset {
						return nil, false
					}
					copy(fullBodyBytes[offset:], chunkFragmentData.Body.Data())
					offset += chunkLen
				} else {
					return nil, false
				}
			}
			return fullBodyBytes, true
		}
	}

	return nil, true
}
